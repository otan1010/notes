Prerequisite: You've followed the instructions in acc_install.

----------------------------
-- 1. Verify installation --
----------------------------
By default there is an example in the dev folder, which we will try to run now to make sure everything works.
- cd into accelerator_project_skeleton/accelerator and run ./daemon.py. This will start the accelerator.
- start another terminal and cd into accelerator_project_skeleton/accelerator. Run ./automatarunner.py
- Running automatarunner.py will run the code in dev/automata.py, which in turn invokes a_example.py in the same folder.
- You will see some feedback in both terminals that the job has been run. Data generated by running this job will be placed in $HOME/accelerator/workdirs/TEST/TEST-0. Since it's "dummy" code no interesting output will be generated, however, and so we'll ignore that for now.
- If it ran without errors we should be fine to continue!

-------------------------
-- 2. Import some data --
-------------------------
The Accelerator has a number of standard methods which are located under accelerator_project_skeleton/accelerator/standard_methods. We'll now use one of those methods (csvimport) to import a data set.

First, however, we'll create a new folder structure from which we'll invoke csvimport.
- Exit (ctrl+c) ./daemon.py in the other terminal window so that the accelerator is not running
- cd into accelerator_project_skeleton 
- remove the dev folder and all its contents: "rm dev/*", "rmdir dev"
- create a new folder named example1: "mkdir example1"
- create a new file: "touch example1/methods.conf"
- create a new file: "touch example1/automata_example1.py"
- create a new file: "touch example1/__init__.py"
- edit conf/framework.conf
-- the method directories should initially be set to: "method_directories=dev,standard_methods"
-- change this to the following to reflect your new folder structure: "method_directories=example1,standard_methods"
-- This will make sure that the accelerator looks for code in the new folder.
-- We can also change where the accelerator looks for data, so we'll do that as well:
-- change the "source_directory=/some/other/path" to "source_directory=${HOME}".
-- This will make the accelerators import methods look for data in your users home folder, as specified by the unix environment variable $HOME.
- Then we need to create the dummy data, so create a file named 'test.csv' under your $HOME folder (run 'echo $HOME' in the terminal if you're unsure where that is). Fill the file with some dummy data, as such:

col1,column2,col3
value1,value2,75431
value2,value2,23235
value1,value2,455453
value3,value2,114232
value4,value7,2897433
value4,value2,342343
value1,value4,323243

- The files you 'touch'ed previously are just empty text files, so let's add some code into one of them:
-- Edit the automata file: "example1/automata_example1.py" with the following code:

def main(urd):
	urd.build('csvimport', options=dict(filename='test.csv'))

This will insert an object of the urd class into the main function, which will invoke the standard method 'csvimport' to run on the file you just created.

- Run ./daemon.py in the other terminal again to start the accelerator
- cd into accelerator_project_skeleton/accelerator and run the following: "./automatarunner.py"
- Note that you'll get an error saying: <No automata "automata" found>. This is because we named our automata file  'automata_example1.py', meaning we'll have to specify the name if the accelerator is to find it.
- Instead run "./automatarunner.py example1", which should run without issues.
- Voil√°, you've imported the file 'test.csv' into the accelerator!

--------------------------
-- 3. Explore some data --
--------------------------
Given you've followed the steps in part 2 you should have some test data to explore, which can be done easily with some accelerator utilities.
- cd into accelerator_project_skeleton/accelerator
- In the previous step you should've gotten some feedback such as this:

WORKSPACE:  Allocate_job "/home/localuseracc/accelerator/workdirs/TEST/TEST-1"
| TEST-1 [csvimport] |
| TEST-1 [csvimport]  completed. (  0.0s) |

- 'TEST-1' (or whatever was created) is what we'll use with the utilities to explore the data
- To use the utilities from the terminal we need to have access to accelerator specific libraries, so we need to activate the correct virtual environment before we proceed.
- Run the following to activate the python3 virtual environment:
-- "source ../venv/py3/bin/activate"
- Now run "./dsinfo TEST-1"
-- This will give you information such as this:

Parent: None
Hashlabel: None
Columns:
    col1     bytes
    col3     bytes
    column2  bytes
3 columns
7 lines

- As you can see the default behavior is to use the top column values as column names. By default the columns themselves are set to contain the data type 'bytes'.
- To explore the actual data we can use dsgrep, as such:
-- dsgrep.py [options] pattern ds [ds [...]] [column [column [...]]
-- As an example, this will search for rows with the value "value1": "./dsgrep.py "value1" TEST-1"

value1  75431   value2
value1  455453  value2
value1  323243  value4

-- This will search for all values, but limit the results to the "col3" column: "./dsgrep.py ".*" TEST-1 col3"

75431
23235
455453
114232
2897433
342343
323243

----------------------------------------------
-- Note: Before proceeding here you should ---
-- get Urd up and running. (Might be a good --
-- idea to have that as part of acc_install --
-- and/or init.py?) --------------------------
----------------------------------------------

1. cd accelerator_project_skeleton/accelerator
2. mkdir database
3. Create database/passwd with entry: "username:password"
4. Add row to conf/framework.conf: "urd=http://localhost:8080"
5. run unix command: "export URD_AUTH='username:password'"
6. run urd: "./urd.py --path database/"

----------------------------------------------
----------------------------------------------
----------------------------------------------

-------------------------
-- 4. Dataset chaining --
-------------------------

automata_example1.py =

from datetime import datetime

def main(urd):
    now = datetime.now().strftime('%Y%m%d %H:%M:%S')

    urd.begin('connlog-raw', now)

    jid_prev = urd.latest('connlog-raw').joblist.jobid

    urd.build('csvimport',
            options=dict(filename='test1.csv'),
            datasets=dict(previous=jid_prev),
            name='connlog-cust-name')

    urd.finish('connlog-raw')

